{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "92bN8qONILGD",
        "colab": {}
      },
      "source": [
        "#import coco dataset & annotations\n",
        "\n",
        "!wget http://images.cocodataset.org/zips/train2017.zip\n",
        "!unzip train2017.zip\n",
        "!rm train2017.zip\n",
        "\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!unzip annotations_trainval2017.zip\n",
        "!rm annotations_trainval2017.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mQlD3QqvaDIU",
        "colab": {}
      },
      "source": [
        "# clone the code from github\n",
        "!git clone https://github.com/walterwht/Unet_Video_segmentation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fsk1VRC65j20",
        "colab": {}
      },
      "source": [
        "#install cocoapi \n",
        "#!git clone https://github.com/cocodataset/cocoapi.git\n",
        "from pycocotools.coco import COCO\n",
        "import pycocotools._mask as coco_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xtdpOvkL5YY0",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from Resnet50backbone_coco21classes import Resnet50Unet\n",
        "from Dataset_Resnet50_coco21Classes import cocodataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eMbtIGmehz5T",
        "colab": {}
      },
      "source": [
        "#resequence 21 classes of the coco dataset\n",
        "\n",
        "allclassid= [0,5, 2, 15, 9, 40, 6,\n",
        " 3, 16, 57, 20, 61 , 17, 18, 4,\n",
        " 1, 59, 19, 58, 7, 63]\n",
        "\n",
        "allclassnms = ['__background__', 'airplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
        " 'car', 'cat', 'chair', 'cow', 'dining table', 'dog', 'horse', 'motorcycle',\n",
        " 'person', 'potted plant', 'sheep', 'couch', 'train', 'tv']\n",
        "\n",
        "for nac in range(len(allclassnms)):\n",
        "  print(\"{}. class name:{}, class id:{}\".format(nac,allclassnms[nac],allclassid[nac]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZXS-8v6x5s91",
        "colab": {}
      },
      "source": [
        "#add data to dataloader \n",
        "batch_size=4\n",
        "trainData = cocodataset(root = 'train2017',annFile = 'annotations/instances_train2017.json',classes = allclassnms, classid = allclassid)\n",
        "data_loader = torch.utils.data.DataLoader(trainData, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "print(\"Len of the datas\".format(len(data_loader)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FcmuOSqqGkss",
        "colab": {}
      },
      "source": [
        "# check the dataset image with mask\n",
        "for e, data in enumerate(data_loader,start=15):\n",
        "    fig2=plt.figure(figsize=(25,25)) \n",
        "    img, Tmask = data\n",
        "    \n",
        "    argm = torch.argmax(Tmask[0],dim=0)\n",
        "\n",
        "    fig2.add_subplot(2,2,1)\n",
        "    plt.imshow(img[0].permute(1,2,0), cmap=\"rainbow\")\n",
        "\n",
        "    fig2.add_subplot(2,2,2)\n",
        "    plt.imshow(argm, cmap=\"rainbow\")\n",
        "    \n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "vV28a1Hs588b",
        "colab": {}
      },
      "source": [
        "#add model & import some pretaindata\n",
        "model=Resnet50Unet(21)\n",
        "model.load_state_dict(torch.load(\"n_classifier0727_21classes_3.pt\"))\n",
        "model = model.to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gcuDcJuVNO6x",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# model checker\n",
        "summary(model, input_size=(3,520,520))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UsgxduQlTFp2",
        "colab": {}
      },
      "source": [
        "# create custom loss function (not work great may be change to lovasz-Softmax will better)\n",
        "\n",
        "#combined dice loss and CrossEntropyLoss \n",
        "\n",
        "def dice_loss(pred, target, smooth = 1.):\n",
        "    pred = pred.contiguous()\n",
        "    target = target.contiguous()    \n",
        "\n",
        "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
        "    \n",
        "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
        "    \n",
        "    return loss.mean()\n",
        "\n",
        "def calc_loss(pred, target, CEL_weight=0.3):\n",
        "     \n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
        "    Tmask = torch.argmax(target,dim=1)\n",
        "    CEL =criterion(pred,Tmask)\n",
        "\n",
        "    pred2 = torch.sigmoid(pred)\n",
        "    dice = dice_loss(pred2, target)\n",
        "\n",
        "    loss = CEL * CEL_weight + dice * (1 - CEL_weight)\n",
        "\n",
        "\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U75LwfEY6JFq",
        "colab": {}
      },
      "source": [
        "#Model tarining\n",
        "\n",
        "#optimizer : turn off the gradient of the pretrain Resnet layer \n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.00005)\n",
        "\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "    model.train() \n",
        "    running_loss = 0.0\n",
        "  \n",
        "    for eed, data  in enumerate(data_loader, start=0):\n",
        "        optimizer.zero_grad()\n",
        "        imgs, labels = data\n",
        "        imgs, labels = imgs.to(device), labels.to(device) # to cuda if it available\n",
        "\n",
        "        predict = model(imgs) # input image to model and get the predict\n",
        "        loss = calc_loss(predict, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        running_loss += loss.item() #save the loss for checking\n",
        "        optimizer.step()\n",
        "\n",
        "        if eed%200 == 199:\n",
        "            print('[%d, %5d] loss: %.5f' % (epoch + 1, eed + 1, running_loss / 20))\n",
        "            running_loss = 0.0\n",
        "\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-gpYTXo692Vq",
        "colab": {}
      },
      "source": [
        "# Save the trained data\n",
        "path = \"n_classifier0730_21classes.pt\"\n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wGXehcgauPDm",
        "colab": {}
      },
      "source": [
        "# import argmax tensor and output a color image\n",
        "\n",
        "def argm_to_colorimg(masks):\n",
        "    #each rgb color code for each classes\n",
        "    colors = np.asarray([(0, 0, 0), (255, 255, 0), (255, 0, 255), (200, 0, 0),(200, 200, 0),\n",
        "                         (200, 0, 200), (150, 0, 0), (150, 150, 0), (150, 0, 150),(100, 0, 0),\n",
        "                         (100, 100, 0), (100, 0, 100), (50, 0, 0), (50, 50, 0),(50, 0, 50),\n",
        "                         (0, 255, 0), (0, 255, 255), (0, 200, 0), (0, 200, 200),(0, 150, 0),\n",
        "                         (0, 150, 150)])\n",
        "\n",
        "    colorimg = np.zeros((masks.shape[0], masks.shape[1],3), dtype=\"float32\")\n",
        "    height, width = masks.shape\n",
        "\n",
        "    for y in range(height):\n",
        "        for x in range(width):\n",
        "          colorimg[y][x]=colors[masks[y][x]]\n",
        "\n",
        "\n",
        "    return colorimg.astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a_z44drR-NmK",
        "colab": {}
      },
      "source": [
        "# test the segmentation by image\n",
        "model.eval()\n",
        "\n",
        "\n",
        "fig=plt.figure(figsize=(20, 20))\n",
        "\n",
        "transform=transforms.Compose([\n",
        "                    transforms.Resize(512),\n",
        "                    transforms.RandomCrop(512),\n",
        "                    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "img = Image.open(\"5.jpg\").convert('RGB')\n",
        "img = transform(img)\n",
        "img = img.unsqueeze(0)\n",
        "img = img.to(device=device, dtype=torch.float32)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    output=model(img)\n",
        "    output=torch.sigmoid(output)\n",
        "    outputF= output.data.cpu().squeeze(0).numpy()\n",
        "    argm = np.argmax(outputF,axis=0)\n",
        "\n",
        "    finalout =argm_to_colorimg(argm)\n",
        "    \n",
        "    fig.add_subplot(2,2,1)\n",
        "    plt.imshow(finalout)\n",
        "    plt.axis('off')\n",
        "\n",
        "    fig.add_subplot(2,2,2)\n",
        "    plt.imshow(argm)\n",
        "    plt.axis('off')\n",
        "    \n",
        "    b = np.unique(argm)\n",
        "    print(allclassnms[b.data]) # which classes in the argmax mask\n",
        "        \n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}